{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQSCaEEC03WPcHy4SM/CD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pksX01/AI-practice/blob/main/Self_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFU1zz87i1Ul"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d_model=2, row_dim=0, col_dim=1):\n",
        "        super().__init__()\n",
        "        self.row_dim = row_dim\n",
        "        self.col_dim = col_dim\n",
        "\n",
        "        self.Wq = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.Wk = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.Wv = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "    def forward(self, embedddings):\n",
        "        q = self.Wq(embedddings)\n",
        "        k = self.Wk(embedddings)\n",
        "        v = self.Wv(embedddings)\n",
        "        similarity = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "        scaled_similarity = similarity/ torch.tensor(k.size(self.col_dim)**0.5)\n",
        "        attention_weights = F.softmax(scaled_similarity, dim=self.col_dim)\n",
        "        attention_scores = torch.matmul(attention_weights, v)\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "4wVatWdajX1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_matrix = torch.Tensor([[1.16, 0.23],\n",
        "                                 [0.57, 1.36],\n",
        "                                 [4.41, -2.16]])\n",
        "encoding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_swd2Lvn9KS",
        "outputId": "cedc2a65-6921-44ea-d7fb-dbbabab2a827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o07QRc-doP5W",
        "outputId": "9a0172ba-80d5-46cf-d67a-ad17f892c14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bd0b6a61b50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "self_attention = SelfAttention(d_model=2, row_dim=0, col_dim=1)\n",
        "self_attention.forward(encoding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okaTI5Y9oZr7",
        "outputId": "4fe8f51f-c59c-4fb1-c9cd-48dad6ec4668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = self_attention.Wq(encoding_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tei6Tmi9oqr1",
        "outputId": "89a723b1-dff3-4be9-baff-202224cfaa21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = self_attention.Wk(encoding_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8UpMVOMo60v",
        "outputId": "939e5fbc-7cce-4508-cc72-c3c3d88c6f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = self_attention.Wv(encoding_matrix)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4YIjAt8o-P0",
        "outputId": "abbddaa6-8bb2-4057-c51a-ce7113de7eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(F.softmax(torch.matmul(q, k.transpose(dim0=0, dim1=1))/torch.tensor(2**0.5), dim=1), v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjugLe_gpAxV",
        "outputId": "694c80d8-2cff-44cf-9568-ea9e5ef8fcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-tm6GRNpk5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
